# Midi-control-Video
My First ML Project with Max/MSP and Wekinator

The URL of the GitHub repository- https://github.com/ZONESOUND/Midi-control-Video

Abstract

The Max patch has a midi input that constantly receiving 5 different parameters, which are ‘the number of notes(int)’, ‘pitch(MIDI)’, ‘velocity(MIDI)’, ‘note duration (ms)’ and the ‘interval time of note events(ms)’. You can adjust the effect with Brightness, Contrast, Saturation, HUE value on video or image to set the presets of visual effects and train it with Wekinator. Thus, you can then play with real time audio-visual effect corresponding to your playing. 

How to run this project?

1.Open the ‘MIDI_Control_Video.maxpat’ inside “Max Patches” folder. Open the Wekinator and load the file inside “Wekinator Project” folder. You can also train by your own.
2.Once you open the Max patch and set the right midi input and output. The default midi output should be the built-in midi library. Click the toggle to open the webcam or play a local video file. 
3.Open Wekinator project, and start to set up the parameters for visual effect. Start training to build up the model. 
4.After finished training, you can start to play along with the real-time audio-visual effect via MIDI keyboard or controller.
